import cv2
import time
import pandas as pd
import numpy as np
from datetime import datetime
import os
from typing import List, Dict

from utils.config import load_config
from utils.logger import setup_logger
from utils.visualizer import Visualizer
from utils.image_utils import apply_perspective_correction, preprocess_for_ocr
from drivers.camera import Camera
from core.detector import ContainerDetector
from services.ocr_worker import ContainerOCR

def resize_frame(frame, scale=0.5):
    """í™”ë©´ í‘œì‹œìš© ë¦¬ì‚¬ì´ì¦ˆ"""
    return cv2.resize(frame, None, fx=scale, fy=scale)

def main():
    # 1. ì„¤ì • ë° ë¡œê±° ì´ˆê¸°í™”
    config = load_config()
    system_conf = config.get('system', {})
    model_conf = config.get('model', {})
    params_conf = config.get('parameters', {})
    
    logger = setup_logger(log_file=system_conf.get('log_file', 'outputs/gate_log.csv'))
    logger.info("=== íƒ€ì„ ìœˆë„ìš° ê¸°ë°˜ ë©€í‹° ì¹´ë©”ë¼ ì¸ì‹ ì‹œìŠ¤í…œ ì‹œì‘ ===")

    # 2. ëª¨ë“ˆ ì´ˆê¸°í™”
    cameras = []
    video_sources = system_conf.get('video_sources', [system_conf.get('video_path', 'data/raw_videos/gate_side2.mp4')])
    
    if isinstance(video_sources, str):
        video_sources = [video_sources]

    try:
        for src in video_sources:
            try:
                cam = Camera(src)
                cameras.append(cam)
                logger.info(f"ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ: {src}")
            except Exception as e:
                logger.error(f"ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨ ({src}): {e}")

        if not cameras:
            logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        detector = ContainerDetector(
            model_path=model_conf.get('yolo_path', 'outputs/yolo_container_ocr/weights/best.pt'),
            default_model=model_conf.get('yolo_default', 'yolo11n.pt'),
            conf_threshold=model_conf.get('conf_threshold', 0.5)
        )
        
        ocr_worker = ContainerOCR(model_name=model_conf.get('ocr_model', 'Qwen/Qwen3-VL-2B-Instruct'))
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. ìƒíƒœ ë³€ìˆ˜ ì„¤ì •
    STATE_IDLE = 0
    STATE_COLLECTING = 1
    STATE_COOLDOWN = 2
    
    current_state = STATE_IDLE
    
    # íŒŒë¼ë¯¸í„°
    collection_window = params_conf.get('collection_window', 60) # ìˆ˜ì§‘ ê¸°ê°„ (í”„ë ˆì„)
    cooldown_frames = params_conf.get('cooldown_frames', 150)    # ì¬ì¸ì‹ ë°©ì§€ ì¿¨ë‹¤ìš´
    perspective_intensity = params_conf.get('perspective_intensity', 0.0)
    
    state_timer = 0
    evidence_bucket = [] # ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ ì •ë³´ë“¤ {'path': ..., 'score': ..., 'cam_id': ...}
    
    history = []
    frame_idx = 0
    temp_dir = system_conf.get('temp_frame_dir', 'temp_frames')
    os.makedirs(temp_dir, exist_ok=True)

    logger.info(f">>> ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ìˆ˜ì§‘ ìœˆë„ìš°: {collection_window}í”„ë ˆì„)")

    while True:
        # --- 1. í”„ë ˆì„ ìˆ˜ì§‘ ---
        frames = []
        for cam in cameras:
            frame = cam.get_frame()
            frames.append(frame)

        if all(f is None for f in frames):
            logger.info("ëª¨ë“  ì˜ìƒ ì†ŒìŠ¤ ì¢…ë£Œ")
            break

        frame_idx += 1
        
        # íƒ€ì´ë¨¸ ê°ì†Œ
        if state_timer > 0:
            state_timer -= 1
            # ìˆ˜ì§‘ ì¢…ë£Œ -> íŒê²° ëª¨ë“œ
            if current_state == STATE_COLLECTING and state_timer == 0:
                logger.info(f"ğŸ›‘ ìˆ˜ì§‘ ì¢…ë£Œ! ì¦ê±° {len(evidence_bucket)}ê±´ ë¶„ì„ ì‹œì‘...")
                
                if evidence_bucket:
                    # 1. ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
                    image_paths = [item['path'] for item in evidence_bucket]
                    
                    # 2. ì¼ê´„ OCR
                    ocr_results = ocr_worker.process_batch(image_paths)
                    
                    # 3. íˆ¬í‘œ
                    final_verdict = ocr_worker.consolidate_results(ocr_results)
                    
                    if final_verdict['found']:
                        final_num = final_verdict['container_number']
                        meta = final_verdict.get('voting_meta', {})
                        logger.info(f"â˜… ìµœì¢… í™•ì •: {final_num} (íˆ¬í‘œ: {meta.get('winner_count')}/{meta.get('total_votes')})")
                        
                        history.append({
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            'frame_id': frame_idx,
                            'container_number': final_num,
                            'voting_result': f"{meta.get('winner_count')}/{meta.get('total_votes')}"
                        })
                    else:
                        logger.info("âŒ ì¸ì‹ ì‹¤íŒ¨: ìœ íš¨í•œ ë²ˆí˜¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    logger.info("âŒ ìˆ˜ì§‘ëœ ì¦ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # ì¿¨ë‹¤ìš´ ì§„ì…
                current_state = STATE_COOLDOWN
                state_timer = cooldown_frames
                evidence_bucket = [] # ë²„í‚· ë¹„ìš°ê¸°
            
            # ì¿¨ë‹¤ìš´ ì¢…ë£Œ -> IDLE
            elif current_state == STATE_COOLDOWN and state_timer == 0:
                current_state = STATE_IDLE
                logger.info("ğŸŸ¢ ëŒ€ê¸° ëª¨ë“œ ì „í™˜ (IDLE)")

        # --- 2. íƒì§€ ë° ìˆ˜ì§‘ ---
        display_frames = []
        
        for i, frame in enumerate(frames):
            if frame is None:
                continue
                
            disp_frame = frame.copy()
            
            # ì¿¨ë‹¤ìš´ ì¤‘ì—” íƒì§€ ìƒëµí•´ì„œ ìì› ì ˆì•½ (ì›í•˜ë©´ ì¼œë„ ë¨)
            if current_state != STATE_COOLDOWN:
                best_box = detector.detect(frame)
                
                if best_box is not None:
                    # ì¢Œí‘œ ë° ì ìˆ˜
                    conf = float(best_box.conf[0])
                    x1, y1, x2, y2 = map(int, best_box.xyxy[0].cpu().numpy())
                    
                    # ì¤‘ì•™ ì •ë ¬ í™•ì¸
                    fh, fw = frame.shape[:2]
                    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                    is_centered = (fw * 0.4 < cx < fw * 0.6) and (fh * 0.25 < cy < fh * 0.75)
                    
                    Visualizer.draw_detection(disp_frame, best_box, is_centered)
                    
                    # [ë¡œì§]
                    # IDLE ìƒíƒœì—ì„œ ì¤‘ì•™ ì •ë ¬ëœ ì»¨í…Œì´ë„ˆ ë°œê²¬ -> ìˆ˜ì§‘ ëª¨ë“œ ì‹œì‘
                    if current_state == STATE_IDLE and is_centered:
                        current_state = STATE_COLLECTING
                        state_timer = collection_window
                        logger.info(f"ğŸ“¸ ê°ì§€ë¨! ìˆ˜ì§‘ ëª¨ë“œ ì‹œì‘ ({collection_window}í”„ë ˆì„)")
                    
                    # COLLECTING ìƒíƒœì—ì„œ ì¢‹ì€ ìƒ·(ì¤‘ì•™ ì •ë ¬) ê³„ì† ìˆ˜ì§‘
                    if current_state == STATE_COLLECTING and is_centered:
                        # ì´ë¯¸ ìˆ˜ì§‘ëœ ê²ƒ ì¤‘ í˜„ì¬ ì¹´ë©”ë¼ì˜ ìµœê³  ì ìˆ˜ í™•ì¸
                        # (ì¹´ë©”ë¼ë‹¹ ë„ˆë¬´ ë§ì´ ìˆ˜ì§‘ë˜ë©´ ëŠë ¤ì§€ë‹ˆ ì œí•œì„ ë‘˜ ìˆ˜ë„ ìˆìŒ)
                        
                        # ROI ì €ì¥
                        pw_pad = int((x2 - x1) * 0.1)
                        ph_pad = int((y2 - y1) * 0.1)
                        px1 = max(0, x1 - pw_pad)
                        py1 = max(0, y1 - ph_pad)
                        px2 = min(fw, x2 + pw_pad)
                        py2 = min(fh, y2 + ph_pad)
                        
                        roi_raw = frame[py1:py2, px1:px2].copy()
                        roi_pre = preprocess_for_ocr(roi_raw)
                        roi_img = apply_perspective_correction(roi_pre, intensity=perspective_intensity)
                        
                        file_path = os.path.join(temp_dir, f"cam{i}_f{frame_idx}_{int(time.time()*1000)}.jpg")
                        cv2.imwrite(file_path, roi_img)
                        
                        # ì¦ê±° ì¶”ê°€
                        evidence_bucket.append({
                            'path': file_path,
                            'score': conf,
                            'cam_id': i
                        })
                        
                        cv2.putText(disp_frame, "COLLECTING", (px1, py1 - 10), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 165, 255), 2)

            display_frames.append(resize_frame(disp_frame, scale=0.4))

        # --- 3. í™”ë©´ ë³‘í•© ë° ìƒíƒœ í‘œì‹œ ---
        if display_frames:
            combined_view = np.hstack(display_frames)
            
            # ìƒíƒœ í…ìŠ¤íŠ¸
            status_map = {0: "IDLE", 1: "COLLECTING", 2: "COOLDOWN"}
            status_color = {0: (0, 255, 0), 1: (0, 165, 255), 2: (0, 0, 255)} # G, Orange, R
            
            s_text = f"Status: {status_map[current_state]}"
            if state_timer > 0:
                s_text += f" ({state_timer})"
            
            cv2.putText(combined_view, s_text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, status_color[current_state], 2)
            cv2.putText(combined_view, f"Evidence: {len(evidence_bucket)}", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)

            cv2.imshow('Multi-Camera Evidence Collector', combined_view)

        # í‚¤ ì…ë ¥
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord(']'):
            perspective_intensity = min(0.5, perspective_intensity + 0.01)
        elif key == ord('['):
            perspective_intensity = max(0.0, perspective_intensity - 0.01)

    for cam in cameras:
        cam.release()
    cv2.destroyAllWindows()
    
    if history:
        log_path = system_conf.get('log_file', 'outputs/gate_access_log.csv')
        pd.DataFrame(history).to_csv(log_path, index=False, encoding='utf-8-sig')
        logger.info(f"ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {log_path}")

if __name__ == "__main__":
    main()
