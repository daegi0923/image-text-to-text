import cv2
import time
import pandas as pd
import numpy as np
from datetime import datetime
import os
from typing import List, Dict

from utils.config import load_config
from utils.logger import setup_logger
from utils.visualizer import Visualizer
from utils.image_utils import apply_perspective_correction, preprocess_for_ocr
from drivers.camera import Camera
from core.detector import ContainerDetector
from services.ocr_worker import ContainerOCR

def resize_frame(frame, scale=0.5):
    """í™”ë©´ í‘œì‹œìš© ë¦¬ì‚¬ì´ì¦ˆ"""
    return cv2.resize(frame, None, fx=scale, fy=scale)

def main():
    config = load_config()
    system_conf = config.get('system', {})
    model_conf = config.get('model', {})
    params_conf = config.get('parameters', {})
    
    logger = setup_logger(log_file=system_conf.get('log_file', 'outputs/gate_log.csv'))
    logger.info("=== ë™ê¸°í™”(Sync) ê¸°ë°˜ ë©€í‹° ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì‹œì‘ ===")

    # 1. ì´ˆê¸°í™”
    camera_units = [] 
    camera_configs = system_conf.get('cameras', [])
    
    if not camera_configs and 'video_sources' in system_conf:
        default_weights = model_conf.get('yolo_path', 'outputs/yolo_container_ocr/weights/best.pt')
        for idx, src in enumerate(system_conf['video_sources']):
            camera_configs.append({'name': f"cam_{idx}", 'source': src, 'weights': default_weights})

    try:
        ocr_worker = ContainerOCR(model_name=model_conf.get('ocr_model', 'Qwen/Qwen3-VL-2B-Instruct'))
        
        for conf in camera_configs:
            name = conf.get('name', 'unknown')
            src = conf.get('source')
            weights = conf.get('weights')
            if not src: continue
            try:
                cam = Camera(src)
                detector = ContainerDetector(
                    model_path=weights,
                    default_model=model_conf.get('yolo_default', 'yolo11n.pt'),
                    conf_threshold=model_conf.get('conf_threshold', 0.5)
                )
                camera_units.append({
                    'cam': cam, 'detector': detector, 'name': name,
                    'fps': cam.fps, # FPS ì •ë³´ ì €ì¥
                    'last_frame_idx': 0
                })
                logger.info(f"âœ… ìœ ë‹›: {name} ({cam.fps:.1f} FPS) | Src: {src}")
            except Exception as e:
                logger.error(f"âŒ ìœ ë‹› ì‹¤íŒ¨ ({name}): {e}")

        if not camera_units: return

    except Exception as e:
        logger.error(f"ì´ˆê¸°í™” ì—ëŸ¬: {e}")
        return

    # 2. ìƒíƒœ ë³€ìˆ˜
    STATE_IDLE = 0
    STATE_COLLECTING = 1
    STATE_COOLDOWN = 2
    current_state = STATE_IDLE
    
    collection_window = params_conf.get('collection_window', 60)
    cooldown_frames = params_conf.get('cooldown_frames', 150)
    perspective_intensity = params_conf.get('perspective_intensity', 0.0)
    
    state_timer = 0
    evidence_bucket = []
    history = []
    temp_dir = system_conf.get('temp_frame_dir', 'temp_frames')
    os.makedirs(temp_dir, exist_ok=True)

    # 3. ë™ê¸°í™” ë³€ìˆ˜
    start_time = time.time()
    global_frame_idx = 0

    logger.info(f">>> ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ë™ê¸°í™” í™œì„±í™”)")

    while True:
        elapsed_time = time.time() - start_time
        global_frame_idx += 1
        
        # --- [Sync] í”„ë ˆì„ ì½ê¸° ---
        active_frames = []
        all_closed = True
        
        for unit in camera_units:
            cam = unit['cam']
            target_frame_count = int(elapsed_time * unit['fps'])
            current_frame_pos = unit['last_frame_idx']
            
            frame = None
            
            # ë’¤ì²˜ì§„ ë§Œí¼ ë¹¨ë¦¬ ê°ê¸° (Skip Frames)
            # ë„ˆë¬´ ë§ì´ ë°€ë ¸ìœ¼ë©´(5ì´ˆ ì´ìƒ) ê·¸ëƒ¥ ì í”„(seek)ê°€ ë‚«ì§€ë§Œ, ì—¬ê¸°ì„  skipìœ¼ë¡œ ì²˜ë¦¬
            frames_to_skip = target_frame_count - current_frame_pos
            
            if frames_to_skip > 0:
                # ë§ˆì§€ë§‰ í•œ ì¥ë§Œ ë””ì½”ë”©í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¼ (grab)
                for _ in range(frames_to_skip - 1):
                    if not cam.cap.grab():
                        break
                    unit['last_frame_idx'] += 1
                
                # ìµœì¢… í”„ë ˆì„ ì½ê¸°
                ret, frame = cam.cap.read()
                if ret:
                    unit['last_frame_idx'] += 1
                else:
                    frame = None # ì˜ìƒ ëë‚¨
            else:
                # ì‹œê°„ì´ ì•ˆ ëìœ¼ë©´ ì´ì „ í”„ë ˆì„ì„ ê·¸ëŒ€ë¡œ ì“°ê±°ë‚˜ ëŒ€ê¸°í•´ì•¼ í•¨
                # í•˜ì§€ë§Œ ë¡œì§ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ê·¸ëƒ¥ ì½ê³  ë„˜ì–´ê° (Over-speed ë°©ì§€ëŠ” sleepìœ¼ë¡œ)
                # ì—¬ê¸°ì„œëŠ” 'ì‹±í¬ ë§ì¶”ê¸°'ê°€ í•µì‹¬ì´ë¯€ë¡œ, ë„ˆë¬´ ë¹ ë¥´ë©´ None ì²˜ë¦¬í•´ì„œ ìŠ¤í‚µí•´ë„ ë¨
                # ì¼ë‹¨ì€ ë§¤ ë£¨í”„ë§ˆë‹¤ ì½ë˜, FPS ë‚®ì€ ì• ëŠ” ê°™ì€ í”„ë ˆì„ ìœ ì§€í•˜ëŠ” ê²Œ ë³µì¡í•˜ë‹ˆ
                # "ìµœì†Œ 1í”„ë ˆì„ì€ ì½ëŠ”ë‹¤"ë¡œ ì²˜ë¦¬ (ë‹¨ìˆœí™”)
                 ret, frame = cam.cap.read()
                 if ret: unit['last_frame_idx'] += 1

            if frame is not None:
                active_frames.append((frame, unit))
                all_closed = False
            else:
                active_frames.append((None, unit))

        if all_closed:
            logger.info("ëª¨ë“  ì˜ìƒ ì¢…ë£Œ")
            break

        # --- ë¡œì§ ì²˜ë¦¬ ---
        if state_timer > 0:
            state_timer -= 1
            if current_state == STATE_COLLECTING and state_timer == 0:
                logger.info(f"ğŸ›‘ ìˆ˜ì§‘ ì¢…ë£Œ (ì¦ê±° {len(evidence_bucket)}ê°œ)")
                if evidence_bucket:
                    # ë¶„ì„ ë° íˆ¬í‘œ
                    image_paths = [e['path'] for e in evidence_bucket]
                    res = ocr_worker.process_batch(image_paths)
                    verdict = ocr_worker.consolidate_results(res)
                    
                    if verdict['found']:
                        num = verdict['container_number']
                        meta = verdict.get('voting_meta', {})
                        logger.info(f"â˜… í™•ì •: {num} ({meta.get('winner_count')}/{meta.get('total_votes')})")
                        history.append({'time': datetime.now(), 'number': num})
                    else:
                        logger.info("âŒ ì¸ì‹ ì‹¤íŒ¨")
                
                current_state = STATE_COOLDOWN
                state_timer = cooldown_frames
                evidence_bucket = []
            
            elif current_state == STATE_COOLDOWN and state_timer == 0:
                current_state = STATE_IDLE
                logger.info("ğŸŸ¢ ëŒ€ê¸° ëª¨ë“œ (IDLE)")

        # --- íƒì§€ ë° í‘œì‹œ ---
        display_frames = []
        any_container_detected_this_frame = False

        for frame, unit in active_frames:
            if frame is None: continue
            
            disp = frame.copy()
            fh, fw = frame.shape[:2]
            
            if current_state != STATE_COOLDOWN:
                best_box = unit['detector'].detect(frame)
                
                if best_box is not None:
                    conf = float(best_box.conf[0])
                    x1, y1, x2, y2 = map(int, best_box.xyxy[0].cpu().numpy())
                    cx, cy = (x1+x2)//2, (y1+y2)//2
                    is_centered = (fw*0.4 < cx < fw*0.6) and (fh*0.25 < cy < fh*0.75)
                    
                    Visualizer.draw_detection(disp, best_box, is_centered)
                    
                    if is_centered:
                        any_container_detected_this_frame = True
                        
                        # [íŠ¸ë¦¬ê±°] IDLE -> COLLECTING
                        if current_state == STATE_IDLE:
                            current_state = STATE_COLLECTING
                            state_timer = collection_window
                            logger.info(f"ğŸ“¸ {unit['name']} ê°ì§€! ìˆ˜ì§‘ ì‹œì‘")
                        
                        # [ìˆ˜ì§‘] COLLECTING
                        if current_state == STATE_COLLECTING:
                            # ì¦ê±° ì €ì¥
                            pw, ph = int((x2-x1)*0.1), int((y2-y1)*0.1)
                            crop = frame[max(0, y1-ph):min(fh, y2+ph), max(0, x1-pw):min(fw, x2+pw)].copy()
                            pre = preprocess_for_ocr(crop)
                            final_img = apply_perspective_correction(pre, intensity=perspective_intensity)
                            
                            path = os.path.join(temp_dir, f"{unit['name']}_{global_frame_idx}.jpg")
                            cv2.imwrite(path, final_img)
                            evidence_bucket.append({'path': path, 'score': conf, 'unit': unit['name']})
                            
                            cv2.putText(disp, "COLLECTING", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 165, 255), 2)

            display_frames.append(resize_frame(disp, scale=0.4))
            
        # [íƒ€ì´ë¨¸ ì—°ì¥] ëˆ„êµ°ê°€ ê³„ì† ë³´ê³  ìˆìœ¼ë©´ íƒ€ì´ë¨¸ ë¦¬ì…‹ (ìµœëŒ€ ì‹œê°„ ì œí•œì„ ë‘ëŠ” ê²ƒë„ ë°©ë²•)
        if current_state == STATE_COLLECTING and any_container_detected_this_frame:
            state_timer = collection_window # íƒ€ì´ë¨¸ë¥¼ ê³„ì† ê½‰ ì±„ì›€ (ì§€ë‚˜ê°ˆ ë•Œê¹Œì§€)

        # í™”ë©´ ì¶œë ¥
        if display_frames:
            combined = np.hstack(display_frames)
            
            status_map = {0: "IDLE", 1: "COLLECTING", 2: "COOLDOWN"}
            color_map = {0: (0,255,0), 1: (0,165,255), 2: (0,0,255)}
            
            cv2.putText(combined, f"{status_map[current_state]} ({state_timer})", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, color_map[current_state], 2)
            cv2.imshow('Sync Multi-Camera System', combined)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'): break
        
    for unit in camera_units: unit['cam'].release()
    cv2.destroyAllWindows()
    
    if history:
        pd.DataFrame(history).to_csv(system_conf.get('log_file', 'outputs/gate_log.csv'), index=False)

if __name__ == "__main__":
    main()
