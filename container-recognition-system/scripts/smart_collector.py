import cv2
import time
import os
import sys
import yaml
import numpy as np
import shutil
from datetime import datetime
from ultralytics import YOLO

# ÌîÑÎ°úÏ†ùÌä∏ Í≤ΩÎ°ú Ï∂îÍ∞Ä
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from drivers.camera import Camera

def load_config():
    path = "configs/settings.yaml"
    if not os.path.exists(path):
        path = "../configs/settings.yaml"
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def resize_for_display(frame, width=480):
    if frame is None: return None
    h, w = frame.shape[:2]
    return cv2.resize(frame, (width, int(h * width / w)))

def detect_in_roi(unit, frame, scale_width=640):
    """
    ÌäπÏ†ï Ïú†ÎãõÏùò ROI ÎÇ¥ Í∞ùÏ≤¥ Í∞êÏßÄ Ïó¨Î∂Ä Î∞òÌôò
    """
    if 'model' not in unit:
        return False, []

    h, w = frame.shape[:2]
    scale = w / scale_width
    small_h = int(h / scale)
    small_frame = cv2.resize(frame, (scale_width, small_h))
    
    # Ìä∏Îü≠(0), Ïª®ÌÖåÏù¥ÎÑà(1)Îßå Í∞êÏßÄ
    results = unit['model'](small_frame, verbose=False, conf=0.5, classes=[0, 1])
    
    detected = False
    boxes = []

    if results:
        for box in results[0].boxes:
            # Ï¢åÌëú Î≥µÏõê
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            x1, x2 = int(x1 * scale), int(x2 * scale)
            y1, y2 = int(y1 * scale), int(y2 * scale)
            cx, cy = (x1+x2)//2, (y1+y2)//2
            
            # ROI Ï≤¥ÌÅ¨
            z = unit['zone']
            zx1, zx2 = int(w*z['x_min']), int(w*z['x_max'])
            zy1, zy2 = int(h*z['y_min']), int(h*z['y_max'])
            
            if zx1 < cx < zx2 and zy1 < cy < zy2:
                detected = True
                boxes.append((x1, y1, x2, y2))
                
    return detected, boxes

def main():
    print("=== üì∏ [Ïä§ÎßàÌä∏] Ìä∏Îü≠ ÏûêÎèô ÏàòÏßëÍ∏∞ (Dual-Check) ===")
    print("FrontÍ∞Ä Ïû°ÏúºÎ©¥ ÏãúÏûë -> BackÏù¥ ÎÜìÏïÑÏ£ºÎ©¥ Ï¢ÖÎ£å")
    print("Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî: Î™®Îç∏ Ï∫êÏã± + Ï°∞Í±¥Î∂Ä Ï∂îÎ°†")
    print("Ï¢ÖÎ£å: Q")

    config = load_config()
    sys_conf = config.get('system', {})
    
    # 1. Ïπ¥Î©îÎùº Î∞è Î™®Îç∏ Î°úÎìú (Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôî)
    cameras = []
    model_cache = {} # Í∞ôÏùÄ Í∞ÄÏ§ëÏπò ÌååÏùºÏùÄ Ìïú Î≤àÎßå Î°úÎìú
    
    base_save_path = "data/dataset/raw_captures"
    os.makedirs(base_save_path, exist_ok=True)
    
    # Master Ï∞æÍ∏∞ Î∞è ÎÇòÎ®∏ÏßÄ ÏÑ§Ï†ï
    # Ï£ºÏùò: Ïó¨Í∏∞ÏÑú 'role'Ïù¥ masterÏù∏ ÎÜàÏùÄ Ìï≠ÏÉÅ Í∞êÏãú, 
    # weightsÍ∞Ä ÏûàÎäî Îã§Î•∏ ÎÜàÎì§(Back View)ÏùÄ ÎÖπÌôî ÎïåÎßå Í∞êÏãú
    
    for conf in sys_conf.get('cameras', []):
        name = conf.get('name')
        role = conf.get('role', 'slave')
        src = conf.get('source')
        weights = conf.get('weights')
        zone = conf.get('detection_zone')
        # [ÏàòÏ†ï] configÏóêÏÑú Î™ÖÏãúÏ†ÅÏúºÎ°ú has_detector Ïó¨Î∂ÄÎ•º Í∞ÄÏ†∏Ïò¥ (Í∏∞Î≥∏Í∞í False)
        config_has_detector = conf.get('has_detector', False)
        
        try:
            cam = Camera(src)
            unit = {
                'name': name,
                'role': role,
                'cam': cam,
                'zone': zone,
                'has_detector': False
            }
            
            # Î™®Îç∏ Î°úÎìú: Î™ÖÏãúÏ†ÅÏúºÎ°ú has_detectorÍ∞Ä TrueÏù¥Í≥† weightsÍ∞Ä ÏûàÎäî Í≤ΩÏö∞Îßå
            if config_has_detector and weights:
                # Ï†àÎåÄ Í≤ΩÎ°ú Î≥ÄÌôò
                if not os.path.isabs(weights):
                     weights = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), weights)
                
                if weights not in model_cache:
                    print(f"‚öñÔ∏è Î™®Îç∏ Î°úÎî© (Ï∫êÏãú): {os.path.basename(weights)}...")
                    model_cache[weights] = YOLO(weights)
                
                unit['model'] = model_cache[weights]
                unit['has_detector'] = True
                print(f"‚úÖ Ïπ¥Î©îÎùº: {name} (Role: {role}) [Detector Active]")
            else:
                # MasterÏù∏Îç∞ detectorÍ∞Ä ÏóÜÏúºÎ©¥ Í≤ΩÍ≥†
                if role == 'master':
                    print(f"‚ö†Ô∏è Í≤ΩÍ≥†: Master({name})Ïóê detector ÏÑ§Ï†ïÏù¥ ÏóÜÏäµÎãàÎã§!")
                print(f"‚úÖ Ïπ¥Î©îÎùº: {name} (Role: {role}) [Monitor Only]")
                
            cameras.append(unit)
                
        except Exception as e:
            print(f"‚ùå Ï¥àÍ∏∞Ìôî Ïã§Ìå® ({name}): {e}")

    # Master(Front) Ï∞æÍ∏∞
    master_unit = next((c for c in cameras if c['role'] == 'master'), None)
    if not master_unit:
        print("üö® Master Ïπ¥Î©îÎùºÍ∞Ä ÏóÜÏäµÎãàÎã§! settings.yaml ÌôïÏù∏.")
        return

    # Back View Ï∞æÍ∏∞ (MasterÍ∞Ä ÏïÑÎãåÎç∞ DetectorÍ∞Ä ÏûàÎäî ÎÜà)
    assist_units = [c for c in cameras if c['role'] != 'master' and c['has_detector']]
    if assist_units:
        print(f"ü§ù Î≥¥Ï°∞ Í∞êÏãú Ïπ¥Î©îÎùº(Exit Monitor): {[u['name'] for u in assist_units]}")
    else:
        print("‚ÑπÔ∏è Î≥¥Ï°∞ Í∞êÏãú Ïπ¥Î©îÎùº ÏóÜÏùå. Master ÌòºÏûê Î∂ÅÏπòÍ≥† Ïû•Íµ¨Ïπ®.")

    # ÏÉÅÌÉú Î≥ÄÏàò
    is_recording = False
    cooldown_counter = 0 
    COOLDOWN_FRAMES = 15 # ÏïΩ 1~2Ï¥à Ïó¨Ïú†
    current_session_dir = None
    frame_count = 0
    save_idx = 0
    
    # Ï§ëÎ≥µ Î∞©ÏßÄ Î≥ÄÏàò
    last_saved_master_frame = None
    last_save_time = 0
    MIN_SAVE_INTERVAL = 0.5 
    FORCE_SAVE_INTERVAL = 2.0 
    MOTION_THRESHOLD = 500000 

    print(">>> ÏãúÏä§ÌÖú Í∞ÄÎèô <<<")

    while True:
        # 1. Î™®Îì† ÌîÑÎ†àÏûÑ ÏùΩÍ∏∞ (Threaded CameraÎùº Îπ†Î¶Ñ)
        frames = {}
        for unit in cameras:
            f = unit['cam'].get_frame()
            if f is None: f = np.zeros((360, 640, 3), dtype=np.uint8)
            frames[unit['name']] = f

        # 2. Í∞êÏßÄ Î°úÏßÅ (Ï°∞Í±¥Î∂Ä Ï∂îÎ°†)
        active_detection = False
        master_viz_boxes = []
        
        # [A] MasterÎäî Ìï≠ÏÉÅ Í∞êÏãú (ÏßÑÏûÖ Ï≤¥ÌÅ¨)
        master_detected, m_boxes = detect_in_roi(master_unit, frames[master_unit['name']])
        if master_detected:
            active_detection = True
            master_viz_boxes = m_boxes

        # [B] Î≥¥Ï°∞ Ïπ¥Î©îÎùºÎäî 'ÎÖπÌôî Ï§ëÏùº ÎïåÎßå' Í∞êÏãú (Ìá¥Ïû• Ï≤¥ÌÅ¨ & ÏûêÏõê Ï†àÏïΩ)
        if is_recording:
            for assist in assist_units:
                assist_detected, _ = detect_in_roi(assist, frames[assist['name']])
                if assist_detected:
                    active_detection = True # Î≥¥Ï°∞ Ïπ¥Î©îÎùºÍ∞Ä Î≥¥Í≥† ÏûàÏúºÎ©¥ Í≥ÑÏÜç ÎÖπÌôî
                    # (ÎîîÎ≤ÑÍ∑∏Ïö©) print(f"Back View {assist['name']} Í∞êÏßÄ Ï§ë...")

        # 3. ÏÑ∏ÏÖò ÏÉÅÌÉú Í¥ÄÎ¶¨ (State Machine)
        if active_detection:
            cooldown_counter = COOLDOWN_FRAMES
            if not is_recording:
                # START
                is_recording = True
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                current_session_dir = os.path.join(base_save_path, f"TRUCK_{timestamp}")
                os.makedirs(current_session_dir, exist_ok=True)
                for c in cameras: os.makedirs(os.path.join(current_session_dir, c['name']), exist_ok=True)
                print(f"üé¨ ÏßÑÏûÖ Í∞êÏßÄ! ÎÖπÌôî ÏãúÏûë -> {timestamp}")
                save_idx = 0
                last_saved_master_frame = None
        else:
            if is_recording:
                cooldown_counter -= 1
                if cooldown_counter <= 0:
                    # STOP
                    is_recording = False
                    print(f"üíæ Ìá¥Ïû• ÌôïÏù∏! ÎÖπÌôî Ï¢ÖÎ£å. (Frames: {save_idx})")
                    current_session_dir = None

        # 4. Ï†ÄÏû• Î°úÏßÅ (Ïù¥Ï†ÑÍ≥º ÎèôÏùº)
        if is_recording and current_session_dir:
            current_time = time.time()
            if (current_time - last_save_time) >= MIN_SAVE_INTERVAL:
                should_save = False
                m_frame = frames[master_unit['name']]
                
                if last_saved_master_frame is None:
                    should_save = True
                else:
                    # ÏõÄÏßÅÏûÑ Ï≤¥ÌÅ¨
                    prev_gray = cv2.cvtColor(last_saved_master_frame, cv2.COLOR_BGR2GRAY)
                    curr_gray = cv2.cvtColor(m_frame, cv2.COLOR_BGR2GRAY)
                    p_small = cv2.resize(prev_gray, (320, 240))
                    c_small = cv2.resize(curr_gray, (320, 240))
                    diff = cv2.absdiff(p_small, c_small)
                    if np.sum(diff) > MOTION_THRESHOLD: should_save = True
                    elif (current_time - last_save_time) > FORCE_SAVE_INTERVAL: should_save = True

                if should_save:
                    for unit in cameras:
                        fname = f"{timestamp}_{save_idx:04d}.jpg"
                        path = os.path.join(current_session_dir, unit['name'], fname)
                        cv2.imwrite(path, frames[unit['name']])
                    save_idx += 1
                    last_saved_master_frame = m_frame.copy()
                    last_save_time = current_time

        frame_count += 1

        # 5. Master ÌôîÎ©¥ Ï∂úÎ†•
        disp = frames[master_unit['name']].copy()
        z = master_unit['zone']
        h, w = disp.shape[:2]
        zx1, zx2 = int(w*z['x_min']), int(w*z['x_max'])
        zy1, zy2 = int(h*z['y_min']), int(h*z['y_max'])
        
        color = (0, 0, 255) if is_recording else (0, 255, 0)
        cv2.rectangle(disp, (zx1, zy1), (zx2, zy2), color, 3)
        for bx in master_viz_boxes:
            cv2.rectangle(disp, (bx[0], bx[1]), (bx[2], bx[3]), (0, 255, 255), 2)
            
        txt = f"REC (Back: {len(assist_units)})" if is_recording else "WAIT"
        cv2.putText(disp, txt, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
        cv2.putText(disp, f"Saved: {save_idx}", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), 2)
        
        cv2.imshow("Smart Collector", resize_for_display(disp, width=800))
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    for c in cameras: c['cam'].release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()