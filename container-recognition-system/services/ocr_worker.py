from typing import Union, List, Dict
from pathlib import Path
import re
import time
import torch
import logging

# ISO ê²€ì¦ ëª¨ë“ˆ
from . import validator as iso6346

# ì—”ì§„ë³„ ì„í¬íŠ¸ (ì§€ì—° ë¡œë”©)
try:
    from paddleocr import PaddleOCR as PaddleEngine
    PADDLE_AVAILABLE = True
except ImportError:
    PADDLE_AVAILABLE = False

try:
    from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
    from qwen_vl_utils import process_vision_info
    QWEN_AVAILABLE = True
except ImportError:
    QWEN_AVAILABLE = False


class ContainerOCR:
    def __init__(self, model_name: str = "paddle"):
        """
        OCR ì—”ì§„ ì´ˆê¸°í™”
        model_name: "paddle" ë˜ëŠ” "Qwen/..." (HuggingFace ê²½ë¡œ)
        """
        self.logger = logging.getLogger(__name__)
        
        # ëª¨ë¸ ì´ë¦„ì— ë”°ë¼ ì—”ì§„ ê²°ì •
        if "paddle" in model_name.lower():
            self.engine_type = "paddle"
            if not PADDLE_AVAILABLE:
                raise ImportError("PaddleOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install paddleocr")
            
            self.logger.info("ğŸš€ PaddleOCR ì´ˆê¸°í™” ì¤‘ (ì–¸ì–´: en, GPU: ìë™ê°ì§€)...")
            # use_angle_cls=True: ë’¤ì§‘íŒ ê¸€ìë„ ë°”ë¡œì¡ì•„ì„œ ì½ìŒ
            # use_gpu=True: GPU ìˆìœ¼ë©´ ì”€ (ì—†ìœ¼ë©´ ìë™ CPU)
            self.model = PaddleEngine(use_angle_cls=True, lang='en', use_gpu=torch.cuda.is_available(), show_log=False)
            self.logger.info("âœ… PaddleOCR ì¤€ë¹„ ì™„ë£Œ!")
            
        else:
            self.engine_type = "qwen"
            if not QWEN_AVAILABLE:
                raise ImportError("Qwen ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
            self.logger.info(f"ğŸ¤– Qwen3-VL ì´ˆê¸°í™” ì¤‘: {model_name}")
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            dtype = torch.bfloat16 if self.device == "cuda" else torch.float32
            
            self.model = Qwen3VLForConditionalGeneration.from_pretrained(
                model_name, torch_dtype=dtype, device_map=self.device
            )
            self.processor = AutoProcessor.from_pretrained(model_name)
            self.model.eval()
            self.logger.info(f"âœ… Qwen3-VL ì¤€ë¹„ ì™„ë£Œ ({self.device})")

    def process_batch(self, image_paths: List[Union[str, Path]]) -> List[Dict[str, any]]:
        """
        ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì¼ê´„ ì²˜ë¦¬ (ì—”ì§„ì— ë”°ë¼ ë¶„ê¸°)
        """
        if not image_paths: return []
        
        start_time = time.time()
        
        if self.engine_type == "paddle":
            results = self._process_batch_paddle(image_paths)
        else:
            results = self._process_batch_qwen(image_paths)
            
        elapsed = time.time() - start_time
        self.logger.info(f"âš¡ Batch OCR ì™„ë£Œ: {len(image_paths)}ì¥ -> {elapsed:.2f}ì´ˆ")
        return results

    def _process_batch_paddle(self, image_paths) -> List[Dict]:
        """PaddleOCR ë°°ì¹˜ ì²˜ë¦¬"""
        results = []
        
        # PaddleOCRì€ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜ì§€ë©´ ë‚´ë¶€ì ìœ¼ë¡œ ë£¨í”„ë¥¼ ëŒì§€ë§Œ ì†ë„ê°€ ë§¤ìš° ë¹ ë¦„
        # (ê³µì‹ì ìœ¼ë¡œ batch_size íŒŒë¼ë¯¸í„°ê°€ ì—†ì–´ì„œ í•œ ì¥ì”© í˜¸ì¶œí•´ë„ ì¶©ë¶„íˆ ë¹ ë¦„)
        # ë§Œì•½ ì§„ì •í•œ ë°°ì¹˜ë¥¼ ì›í•˜ë©´ PP-OCRv4 ì¶”ë¡  ëª¨ë¸ì„ ì§ì ‘ ì„œë¹™í•´ì•¼ í•¨
        
        for path in image_paths:
            img_path_str = str(path)
            try:
                # cls=True: ë°©í–¥ ë³´ì •
                ocr_result = self.model.ocr(img_path_str, cls=True)
                
                # ê²°ê³¼ íŒŒì‹±: í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
                full_text = ""
                conf_sum = 0
                count = 0
                
                if ocr_result and ocr_result[0]:
                    # ocr_result[0] -> [ [ [[x,y],..], ("TEXT", 0.99) ], ... ]
                    texts = [line[1][0] for line in ocr_result[0]]
                    confs = [line[1][1] for line in ocr_result[0]]
                    full_text = " ".join(texts)
                    conf_sum = sum(confs)
                    count = len(confs)
                
                avg_conf = conf_sum / count if count > 0 else 0.0
                
                # ì»¨í…Œì´ë„ˆ ë²ˆí˜¸ ì¶”ì¶œ ë¡œì§
                info = self._parse_container_number(full_text)
                info.update({
                    'image_path': img_path_str,
                    'raw_output': full_text,
                    'confidence': avg_conf
                })
                results.append(info)
                
            except Exception as e:
                self.logger.error(f"PaddleOCR Error ({path}): {e}")
                results.append({'found': False, 'image_path': img_path_str, 'error': str(e)})
                
        return results

    def _process_batch_qwen(self, image_paths) -> List[Dict]:
        """Qwen-VL ë°°ì¹˜ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)"""
        # ... (ì•„ê¹Œ ì§  ë°°ì¹˜ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
        # ì—¬ê¸°ì„œëŠ” ì§€ë©´ ê´€ê³„ìƒ í•µì‹¬ë§Œ ë‚¨ê¹€, ì‹¤ì œë¡œëŠ” ì•„ê¹Œ ì‘ì„±í•œ ì½”ë“œ ì „ì²´ê°€ ë“¤ì–´ê°
        # (ë„¤ê°€ ì›í•˜ë©´ ì „ì²´ ë‹¤ì‹œ ì¨ì¤Œ)
        batch_messages = [self._build_prompt(str(p)) for p in image_paths]
        texts = [self.processor.apply_chat_template(m, tokenize=False, add_generation_prompt=True) for m in batch_messages]
        image_inputs, video_inputs = process_vision_info(batch_messages)
        
        inputs = self.processor(text=texts, images=image_inputs, videos=video_inputs, padding=True, return_tensors="pt")
        inputs = inputs.to(self.device)
        
        with torch.no_grad():
            gen_ids = self.model.generate(**inputs, max_new_tokens=50)
            trimmed = [out[len(in_):] for in_, out in zip(inputs.input_ids, gen_ids)]
            responses = self.processor.batch_decode(trimmed, skip_special_tokens=True)
            
        results = []
        for i, text in enumerate(responses):
            info = self._parse_container_number(text)
            info['image_path'] = str(image_paths[i])
            results.append(info)
        return results

    def _build_prompt(self, image_path):
        return [{"role": "user", "content": [{"type": "image", "image": image_path}, {"type": "text", "text": "Extract container number (ISO 6346)"}]}]

    def _parse_container_number(self, text: str) -> Dict[str, any]:
        # ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°
        cleaned = re.sub(r'[^A-Z0-9]', '', text.upper())
        # íŒ¨í„´ ë§¤ì¹­ (XXXX 123456 7)
        match = re.search(r'([A-Z]{3}[UJRZ])(\d{6})(\d)', cleaned)
        
        if match:
            full = match.group(0)
            valid, calc = iso6346.validate_container_number(full)
            return {
                'container_number': iso6346.format_container_number(full),
                'found': True,
                'check_digit_valid': valid
            }
        return {'container_number': None, 'found': False}

    def consolidate_results(self, results: List[Dict]) -> Dict:
        # íˆ¬í‘œ ë¡œì§ (ê¸°ì¡´ ë™ì¼)
        if not results: return {'found': False}
        candidates = {}
        for r in results:
            if not r.get('found'): continue
            num = r['container_number']
            if num not in candidates: candidates[num] = {'count':0, 'valid': r.get('check_digit_valid')}
            candidates[num]['count'] += 1
            if r.get('check_digit_valid'): candidates[num]['valid'] = True
            
        if not candidates: return {'found': False}
        best = sorted(candidates.items(), key=lambda x: (x[1]['valid'], x[1]['count']), reverse=True)[0]
        return {'found': True, 'container_number': best[0], 'voting_meta': best[1]}
