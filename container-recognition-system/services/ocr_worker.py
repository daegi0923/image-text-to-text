from typing import Union, List, Dict
from pathlib import Path
import re
import time
import torch
import logging
import os
import sys

# [Windows DLL ê²½ë¡œ ê°•ì œ ì£¼ì…]
# PaddleOCRì´ pipë¡œ ì„¤ì¹˜ëœ nvidia-cudnn-cu12ì˜ DLLì„ ëª» ì°¾ì„ ë•Œ í•´ê²°ì±…
if os.name == 'nt':
    import site
    try:
        # site-packages ê²½ë¡œ ì°¾ê¸°
        site_packages = site.getsitepackages()
        for sp in site_packages:
            cudnn_bin = os.path.join(sp, 'nvidia', 'cudnn', 'bin')
            cublas_bin = os.path.join(sp, 'nvidia', 'cublas', 'bin')
            
            if os.path.exists(cudnn_bin):
                os.add_dll_directory(cudnn_bin)
                # PATHì—ë„ ì¶”ê°€ (êµ¬í˜• í˜¸í™˜)
                os.environ['PATH'] = cudnn_bin + os.pathsep + os.environ['PATH']
                print(f"DEBUG: Added DLL dir -> {cudnn_bin}")
                
            if os.path.exists(cublas_bin):
                os.add_dll_directory(cublas_bin)
                os.environ['PATH'] = cublas_bin + os.pathsep + os.environ['PATH']
                print(f"DEBUG: Added DLL dir -> {cublas_bin}")
    except Exception as e:
        print(f"Warning: Failed to add DLL directory: {e}")

# ISO ê²€ì¦ ëª¨ë“ˆ
from . import validator as iso6346

# ì—”ì§„ë³„ ì„í¬íŠ¸ (ì§€ì—° ë¡œë”©)
try:
    from paddleocr import PaddleOCR as PaddleEngine
    PADDLE_AVAILABLE = True
except ImportError:
    PADDLE_AVAILABLE = False

try:
    from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
    from qwen_vl_utils import process_vision_info
    QWEN_AVAILABLE = True
except ImportError:
    QWEN_AVAILABLE = False


class ContainerOCR:
    def __init__(self, model_name: str = "paddle"):
        """
        OCR ì—”ì§„ ì´ˆê¸°í™”
        model_name: "paddle" ë˜ëŠ” "Qwen/..." (HuggingFace ê²½ë¡œ)
        """
        self.logger = logging.getLogger(__name__)
        
        # ëª¨ë¸ ì´ë¦„ì— ë”°ë¼ ì—”ì§„ ê²°ì •
        if "paddle" in model_name.lower():
            self.engine_type = "paddle"
            if not PADDLE_AVAILABLE:
                raise ImportError("PaddleOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install paddleocr")
            
            self.logger.info("ğŸš€ PaddleOCR ì´ˆê¸°í™” ì¤‘ (ì–¸ì–´: en, GPU: ìë™ê°ì§€)...")
            # use_angle_cls=True: ë’¤ì§‘íŒ ê¸€ìë„ ë°”ë¡œì¡ì•„ì„œ ì½ìŒ
            # use_gpu ì˜µì…˜ ì œê±° (ìë™ ê°ì§€ ìœ„ì„)
            self.model = PaddleEngine(use_angle_cls=True, lang='en')
            self.logger.info("âœ… PaddleOCR ì¤€ë¹„ ì™„ë£Œ!")
            
        else:
            self.engine_type = "qwen"
            if not QWEN_AVAILABLE:
                raise ImportError("Qwen ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
            self.logger.info(f"ğŸ¤– Qwen3-VL ì´ˆê¸°í™” ì¤‘: {model_name}")
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            dtype = torch.bfloat16 if self.device == "cuda" else torch.float32
            
            self.model = Qwen3VLForConditionalGeneration.from_pretrained(
                model_name, torch_dtype=dtype, device_map=self.device
            )
            self.processor = AutoProcessor.from_pretrained(model_name)
            self.model.eval()
            self.logger.info(f"âœ… Qwen3-VL ì¤€ë¹„ ì™„ë£Œ ({self.device})")

    def process_batch(self, image_paths: List[Union[str, Path]]) -> List[Dict[str, any]]:
        """
        ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì¼ê´„ ì²˜ë¦¬ (ì—”ì§„ì— ë”°ë¼ ë¶„ê¸°)
        """
        if not image_paths: return []
        
        start_time = time.time()
        
        if self.engine_type == "paddle":
            results = self._process_batch_paddle(image_paths)
        else:
            results = self._process_batch_qwen(image_paths)
            
        elapsed = time.time() - start_time
        self.logger.info(f"âš¡ Batch OCR ì™„ë£Œ: {len(image_paths)}ì¥ -> {elapsed:.2f}ì´ˆ")
        return results

    def _process_batch_paddle(self, image_paths) -> List[Dict]:
        """PaddleOCR ë°°ì¹˜ ì²˜ë¦¬ (ì„¸ë¡œ í…ìŠ¤íŠ¸ ëŒ€ì‘ íšŒì „ ë¡œì§ ì¶”ê°€)"""
        results = []
        import cv2
        import numpy as np

        for path in image_paths:
            img_path_str = str(path)
            
            # 1. ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
            original_img = cv2.imread(img_path_str)
            if original_img is None:
                results.append({'found': False, 'image_path': img_path_str, 'error': 'Image load failed'})
                continue

            # ì‹œë„í•  ì´ë¯¸ì§€ ëª©ë¡ (ì›ë³¸ -> ì‹œê³„90 -> ë°˜ì‹œê³„90)
            # (ì´ë¯¸ì§€ ê°ì²´, íšŒì „ê°ë„ì„¤ëª…)
            attempts = [
                (original_img, "Original"),
                (cv2.rotate(original_img, cv2.ROTATE_90_CLOCKWISE), "Rot90_CW"),
                (cv2.rotate(original_img, cv2.ROTATE_90_COUNTERCLOCKWISE), "Rot90_CCW")
            ]
            
            best_result = {'found': False, 'container_number': None, 'confidence': 0.0}
            
            for img, angle_desc in attempts:
                try:
                    # PaddleOCRì— numpy array ì§ì ‘ ì „ë‹¬ ê°€ëŠ¥
                    ocr_result = self.model.ocr(img)
                    
                    full_text = ""
                    conf_sum = 0
                    count = 0
                    valid_lines = []
                    
                    if ocr_result:
                        if isinstance(ocr_result, list):
                            for item in ocr_result:
                                if not item: continue
                                if isinstance(item, list):
                                    for line in item:
                                        if isinstance(line, dict) and 'rec_texts' in line:
                                            valid_lines.extend(zip(line['rec_texts'], line.get('rec_scores', [0]*len(line['rec_texts']))))
                                        elif isinstance(line, list) and len(line) >= 2 and isinstance(line[1], tuple):
                                            valid_lines.append(line[1])
                                elif isinstance(item, dict) and 'rec_texts' in item:
                                    valid_lines.extend(zip(item['rec_texts'], item.get('rec_scores', [0]*len(item['rec_texts']))))

                    if valid_lines:
                        texts = [txt for txt, conf in valid_lines]
                        confs = [float(conf) for txt, conf in valid_lines]
                        full_text = " ".join(texts)
                        conf_sum = sum(confs)
                        count = len(confs)
                    
                    avg_conf = conf_sum / count if count > 0 else 0.0
                    
                    # íŒŒì‹± ì‹œë„
                    info = self._parse_container_number(full_text)
                    
                    # ì°¾ì•˜ìœ¼ë©´ ì¦‰ì‹œ ì±„íƒ (ë‹¨, ì²´í¬ ë””ì§€íŠ¸ ìœ íš¨í•œ ê±¸ ìš°ì„ )
                    if info['found']:
                        info.update({
                            'image_path': img_path_str,
                            'raw_output': full_text,
                            'confidence': avg_conf,
                            'rotation_used': angle_desc
                        })
                        
                        # ì²´í¬ ë””ì§€íŠ¸ ë§ìœ¼ë©´ ë” ë³¼ ê²ƒë„ ì—†ì´ í™•ì •
                        if info.get('check_digit_valid'):
                            best_result = info
                            break # ë£¨í”„ íƒˆì¶œ
                        
                        # ì²´í¬ ë””ì§€íŠ¸ í‹€ë ¤ë„ ì¼ë‹¨ í›„ë³´ë¡œ ë“±ë¡ (ë‹¤ë¥¸ ê°ë„ì—ì„œ ë” ì¢‹ì€ ê²Œ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë‹ˆ break ì•ˆ í•¨)
                        if avg_conf > best_result.get('confidence', 0):
                            best_result = info
                    
                except Exception as e:
                    self.logger.warning(f"OCR Fail ({angle_desc}): {e}")
            
            # 3ë²ˆ ë‹¤ í•´ë´¤ëŠ”ë°ë„ ì—†ìœ¼ë©´ ì‹¤íŒ¨ ì²˜ë¦¬, í•˜ë‚˜ë¼ë„ ê±´ì¡Œìœ¼ë©´ ì„±ê³µ
            if best_result.get('found'):
                if best_result.get('rotation_used') != "Original":
                    self.logger.info(f"ğŸ”„ íšŒì „ ì¸ì‹ ì„±ê³µ ({img_path_str}): {best_result['rotation_used']} -> {best_result['container_number']}")
                results.append(best_result)
            else:
                results.append({'found': False, 'image_path': img_path_str, 'raw_output': '', 'confidence': 0})
                
        return results

    def _process_batch_qwen(self, image_paths) -> List[Dict]:
        """Qwen-VL ë°°ì¹˜ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)"""
        # ... (ì•„ê¹Œ ì§  ë°°ì¹˜ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
        # ì—¬ê¸°ì„œëŠ” ì§€ë©´ ê´€ê³„ìƒ í•µì‹¬ë§Œ ë‚¨ê¹€, ì‹¤ì œë¡œëŠ” ì•„ê¹Œ ì‘ì„±í•œ ì½”ë“œ ì „ì²´ê°€ ë“¤ì–´ê°
        # (ë„¤ê°€ ì›í•˜ë©´ ì „ì²´ ë‹¤ì‹œ ì¨ì¤Œ)
        batch_messages = [self._build_prompt(str(p)) for p in image_paths]
        texts = [self.processor.apply_chat_template(m, tokenize=False, add_generation_prompt=True) for m in batch_messages]
        image_inputs, video_inputs = process_vision_info(batch_messages)
        
        inputs = self.processor(text=texts, images=image_inputs, videos=video_inputs, padding=True, return_tensors="pt")
        inputs = inputs.to(self.device)
        
        with torch.no_grad():
            gen_ids = self.model.generate(**inputs, max_new_tokens=50)
            trimmed = [out[len(in_):] for in_, out in zip(inputs.input_ids, gen_ids)]
            responses = self.processor.batch_decode(trimmed, skip_special_tokens=True)
            
        results = []
        for i, text in enumerate(responses):
            info = self._parse_container_number(text)
            info['image_path'] = str(image_paths[i])
            results.append(info)
        return results

    def _build_prompt(self, image_path):
        return [{"role": "user", "content": [{"type": "image", "image": image_path}, {"type": "text", "text": "Extract container number (ISO 6346)"}]}]

    def _parse_container_number(self, text: str) -> Dict[str, any]:
        # ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°
        cleaned = re.sub(r'[^A-Z0-9]', '', text.upper())
        # íŒ¨í„´ ë§¤ì¹­ (XXXX 123456 7)
        match = re.search(r'([A-Z]{3}[UJRZ])(\d{6})(\d)', cleaned)
        
        if match:
            full = match.group(0)
            valid, calc = iso6346.validate_container_number(full)
            return {
                'container_number': iso6346.format_container_number(full),
                'found': True,
                'check_digit_valid': valid
            }
        return {'container_number': None, 'found': False}

    def consolidate_results(self, results: List[Dict]) -> Dict:
        # íˆ¬í‘œ ë¡œì§ (ê¸°ì¡´ ë™ì¼)
        if not results: return {'found': False}
        candidates = {}
        for r in results:
            if not r.get('found'): continue
            num = r['container_number']
            if num not in candidates: candidates[num] = {'count':0, 'valid': r.get('check_digit_valid')}
            candidates[num]['count'] += 1
            if r.get('check_digit_valid'): candidates[num]['valid'] = True
            
        if not candidates: return {'found': False}
        best = sorted(candidates.items(), key=lambda x: (x[1]['valid'], x[1]['count']), reverse=True)[0]
        return {'found': True, 'container_number': best[0], 'voting_meta': best[1]}